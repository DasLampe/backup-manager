{"body":"# Backup Manager: How to backup with RSYNC, TAR, CRON and GPG\r\n\r\nthe aim of this post is to describe how I have created my modest personal backup that I use during my working days. I will not expend myself on the importance of Backing up your files, but since it's not Rocket Science, I will spend more time describing the commands and tools I use with their related options since there are some unix tricks that are good to know.\r\n\r\ncreated_on: 01/12/2011 22:15\r\n\r\n## Context\r\n\r\nI really like the principle of the Apple Time Capsule or the Dropbox,\r\nthat I use on my personal computers, but these solutions are not\r\nsuitable, at least in my case, for a corporate use. Time capsule is not\r\nreally scalable when you have too many connected machines and concerning\r\nDropBox I'm not comfortable to store confidential documents in a shared\r\ndrive handle by a third company. That's why sometimes it's easier to use\r\nwhat you have usually at your disposal, for my part that is to say a Unix\r\nOperating System and all the tools that come with it.\r\n\r\nAs described in the title, I'm using exclusively Unix tools like RSYNC\r\nfor the remote copy, and CRON for the tasks scheduling and some other\r\nUnix sugars to have this working all together. I have set a predefined\r\nfolder structure where I'm storing my backed up files, and have a file\r\narchiver with a rotation system that compresses and groups snapshots\r\ntogether.  \r\n\r\nAt the time I'm writing this article, I know that there are plenty\r\nOpenSource softwares that provide nearly the same features that I'm\r\npresenting here, but I like to do this kind of scripting task to train\r\nmyself. I love programming, I love practicing and for me the best way to\r\nimprove your skills is by practicing again and again and again...\r\n\r\nSo to sum up, the objective of this article is to create step by step a\r\nsimple but efficient backup solution with recognized standard tools to\r\nprovide at least the following features:\r\n\r\n* **Regular**       : Scheduled at a regular frequency\r\n* **Unobstructive** : ran as a background job and not require any manual intervention\r\n* **Incremental**   : save only the  increments of change between points in time\r\n* **Snapshots**     : Several instaneous copy of the concerned folder\r\n* **Fast**          : Need to be executed rapidly without being blocker\r\n* **Secured**       : To have the archives encrypted to be stored on external systems\r\n* **Consistent**    : Need to preserve files, links, rights and dates\r\n\r\nIn the next 5 sections I'll try as far as I can to go about many details of the tools and\r\ntechnics we will be using.\r\n\r\n1. Data repository model\r\n2. Retrieve files to create snapshots with RSYNC\r\n3. Create encrypted and compressed archives\r\n4. Schedule the backup tasks\r\n5. final script and cron tab\r\n\r\n## Data repository models\r\n\r\nI'll start this section by describing the Folder structure that\r\nrepresents my repository model, which aimed to be an incremental. \r\n\r\n### The layout\r\n\r\nThe folder structure that I'm using is composed by a main root folder\r\nnamed `backup` here, within which I set 2 folders (`archives` and\r\n`snapshots`) and a symbolic link named `current`.  I will explain the\r\nresponsibilities of all of them afterword, but first here is a small\r\nrepresentation of it:\r\n\r\n```\r\nbackups\r\n|-- archives\r\n|   |-- 20111121.tar.gz.gpg\r\n|   `-- 20111122.tar.gz.gpg\r\n|-- current -> /tmp/backups/snapshots/201111232314\r\n`-- snapshots\r\n    |-- 201111232305\r\n    |-- 201111232310\r\n    `-- 201111232314\r\n```\r\n\r\nTo keep things simple and to not bother you with understandable paths,\r\nI'll handle this layout by defining the variables that I'll use in all\r\nmy future commands.\r\n\r\n```bash\r\nNOW=$(date +%Y%m%d%H%M)\r\nYESTERDAY=$(date -v -1d +%Y%m%d)\r\n\r\n# Backup Configuration\r\nBACKUP_HOME=\"/tmp/backups\"\r\nCURRENT_LINK=\"$BACKUP_HOME/current\"\r\nSNAPSHOT_DIR=\"$BACKUP_HOME/snapshots\"\r\nARCHIVES_DIR=\"$BACKUP_HOME/archives\"\r\n```\r\n\r\n#### The Snapshots folder\r\n\r\nThe definition of Snapshot is a copy of your files at a given instant,\r\nthink of it as a Photo of your files by an instant camera. This kind of\r\nbackup are useful when you have several snapshots for the current day, to be able to recover easily a single file or folder from few hours earlier. \r\n\r\nWe will need to take several snapshots a day, let's say one hourly\r\nduring the working day, which is not so huge since it will not exceed a dozen per day. For practical reasons, that you could figure out, they\r\nare not compressed neither archived in order to recover a file easily. \r\n\r\nAll the snapshots will be stored under\r\n`backups/snapshots/YYYYMMDDHHMM/`.  And to keep snapshots fast and\r\nefficient in term of disk usage, I will use hard links between\r\nsnapshots. This technic is available in RSYNC and will be detailed\r\nbelow.\r\n\r\n#### Archives\r\n\r\nIf we want to preserve your disc space, we should think about archiving old backups. No need to keep definitely all the snapshots folders since you rarely need to browse files older than one or two days. That's why we will create an archive everyday with the content of the previous day. \r\n\r\nAll the previous snapshots will be gathered in an weekly, monthly and yearly encrypted backups archives. To do so we will use `tar`, compress with gunzip and encrypt with GnuPG.\r\n\r\n#### Current\r\n\r\n`current` is a symbolic link pointing to the last snapshot folder. This reference will be used in the future command lines, for example to request rsync to hard link to it.\r\n\r\n## Retrieve files to create snapshots with RSYNC.\r\n\r\n### Rsync\r\n\r\nRsync is an incremental file transfer software which synchronizes files\r\nand directory from a source to a destination by sending only the delta\r\nbetween them. Rsync is a good fit for our requirements, and has a lot of\r\noptions available that will let us tune it easily to our needs.\r\n\r\nHere is the command we will use, with its options:\r\n\r\n```bash\r\nrsync --hard-links --archive --compress --link-dest=$CURRENT_LINK $BACKUP_SOURCE_DIR $SNAPSHOT_DIR/$NOW\r\n```\r\n\r\nThe options are self descriptives, but let's detail them to be sure to\r\nunderstand their roles:\r\n\r\n* `--compress` or `-z`: means that the compression will be used to reduce\r\n  the size of data sent.\r\n* `--hard-links` and `--link-dest=DIR`: hard link to files in DIR when\r\n  unchanged. I use this option to optimize the disk space since only\r\nfiles updated or newly created will consume disk space. By the way, it also\r\naddresses the speed issue. I use the path to the `current` symlink to\r\nmake sure that the hard link are executed on the most recent update.\r\n* `--archive` or `-a`: is a shortcut for several options that acts like\r\n  if you were creating a tar archive using the \"tar pipe\" technic, that is to\r\nsay:\r\n   * recurse into directories\r\n   * copy symlinks as symlinks\r\n   * preserve permissions, times, group, owner and device\r\n\r\n`du` displays disk usage statistics, if you want to confirm hard links are working fine, you can execute the `du -sch` on all the snapshots like this:\r\n\r\n```\r\ndu -sch backups/snapshots/*\r\n\r\n143M backups/snapshots/201112010900\r\n 16K backups/snapshots/201112010930\r\n 16K backups/snapshots/201112011000\r\n 35M backups/snapshots/201112011030\r\n ...\r\n178M total\r\n```\r\n\r\n* `-s` Displays an entry for each specified file.\r\n* `-c` Displays a grand total.\r\n* `-h` Human readable output.\r\n\r\n**Warning**: I discovered it's not working with SAMBA NTFS drives because this filesystem does not understand hard links and it simply duplicates the files.\r\n\r\nReferences:\r\n\r\n* [The tar-pipe](http://blog.extracheese.org/2010/05/the-tar-pipe.html)\r\n   \r\n### Rotation management\r\n\r\n#### Chained Commands \r\nEach time a snapshot backup has been successfully finished, we relink the symbolic link `current` to this one. For this, I'm using the Bash chained commands with an AND conditional execution.\r\n\r\n```bash\r\ncommand1 && command2\r\n```\r\n\r\n`command2` is executed if, and only if, `command1` succeeds\r\n\r\n```bash\r\nrsync --hard-links --archive --compress --link-dest=$CURRENT_LINK $BACKUP_SOURCE_DIR $SNAPSHOT_DIR/$NOW && ln -snf $(ls -1d $SNAPSHOT_DIR/* | tail -n1) $CURRENT_LINK\r\n```\r\n\r\n#### Symbolic Link\r\n\r\nHere is the way we will create the symbolic link:\r\n\r\n```bash\r\nln -snf $(ls -d1 snapshots | tail -n1) current\r\n```\r\n\r\nAnd here are the details of the different options used:\r\n\r\n* `-s` obviously, to specify that is a symbolic link\r\n* `-f` to force the override of the existing link\r\n* `-n` do not follow the target if it's already a symlink.\r\n\r\nBe aware that without the `-n` option, the `ln` command will act as if you were requesting it to link the last snapshot inside of the previous one, like this way:\r\n\r\n```\r\nbackups\r\n`-- current -> snapshots/201111201646\r\n  |-- 201111220901 -> snapshots/201111220901\r\n  |-- Downloads \r\n  ...\r\n```\r\n\r\n#### Subshell Command substitution\r\n\r\nTo find out the last snapshot to link to the `current` folder, I\r\nlist the folders in the `snapshots` directory, formatted as one entry per\r\nline, that I pipe with `tail` to get the last entry.\r\n\r\n```bash\r\nls -d1 snapshots | tail -n1\r\n```\r\n\r\nSince I want to use the result of this command directly in my `ln`\r\ncommand, I'm using the Subshell Command Substitution offered by Bash.\r\n\r\n```bash\r\n$( <COMMANDS> )\r\n```\r\n\r\nThe command substitution returns the `stdout` data after running the\r\ncommand in a subshell. Everything inside the parentheses is executed in\r\na separate instance of bash.\r\n\r\n## Create encrypted and compressed archives\r\n\r\nTo preserve disk space and to keep the backup folder manageable, we need\r\nto find all the snapshots from the previous day, and create a compressed\r\ntimestamped archive. Then we will delete them once the archive successfully created.\r\n\r\n### Compute dates\r\n\r\nAll this script long, we will be using dates several time for the\r\nfile names timestamps or to select eligible files for the rotations.\r\nTo keep the date coherent in the whole script, this is preferable to compute\r\nthem once at the beginning of the script to prevent sides effects.\r\n\r\nHere is how we are retrieving the current and past's dates:\r\n\r\n```bash\r\nNOW=$(date +%Y%m%d%H%M)\r\nYESTERDAY=$(date -v -1d +%Y%m%d)\r\n```\r\n\r\nDate options\r\n\r\n* `-v-1d` return the value of the current date -1 day\r\n* `+%Y%m%d` format the output with the YYYYMMDD format\r\n\r\n### Create the archive\r\n\r\nNow that we have the yesterday's date, let's create the compressed archive\r\nwith all the snapshots folders of this day if they exist, and remove them\r\nin case of success, using a chained command.\r\n\r\nWe first test if the snapshots folder contains some subfolders matching\r\nthe yesterday timestamp, by listing only folders, redirecting the errors\r\nto /dev/null and counting lines of the output.\r\n\r\n```bash\r\nif [ $(ls -d $SNAPSHOT_DIR/$YESTERDAY* 2> /dev/null | wc -l) != \"0\" ]\r\nthen\r\n  tar -czf $ARCHIVES_DIR/$YESTERDAY.tar.gz $SNAPSHOT_DIR/$YESTERDAY* && rm -rf $SNAPSHOT_DIR/$YESTERDAY*\r\nfi\r\n```\r\n\r\nTar options:\r\n\r\n* `-c` create an archive\r\n* `-z` compress the archive witt gunzip\r\n* `-f` force the creation of the archive \r\n\r\n### Encrypt the archives with GPG\r\n\r\nThe best backup files are the one you store far from the source file,\r\nwhich means some security risks. If you store your backups on shared drive or\r\nsimply if you have confidential information, you should think about\r\nencrypt them.\r\n\r\nWhen we start talking about encryption on Unix, the tool that comes first in mind is GnuPG, a complete OpenPGP implementation. It's simple and effective and is not limited to emails.\r\n\r\nI'll not describe how to install, setup and generate keys since there\r\nare plenty sites doing it the right way. I will link some of them in\r\nthe references of this section.\r\n\r\nIn my case, I encrypt the archive with the following command:\r\n\r\n```\r\ngpg -r anouar@adlani.com --encrypt-files $ARCHIVES_DIR/$YESTERDAY.tar.gz\r\n```\r\n\r\nWhich means: encrypt the archive to be decrypted only by the public key of\r\nanouar@adlani.com.\r\n\r\nThe GPG encryptions options:\r\n\r\n* `-r` the recipient name or email used to retrieve the public key\r\n* `--encrypt-files` encrypt the \r\n\r\nWhen you will need to decrypt the archive, the only thing you have to do is call the following command.\r\n\r\n```\r\ngpg --decrypt-files $ARCHIVES_DIR/$YESTERDAY.tar.gz.gpg\r\n```\r\n\r\nDuring the decryption process you will be asked to enter your passphrase:\r\n\r\n```\r\nYou need a passphrase to unlock the secret key for user:\r\n\" Anouar ADLANI (aadlani) <anouar@adlani.com> \"\r\n2048 bits RSA key, ID 840212D2, created 2011-11-23 (main key ID 540DC0B8)\r\n\r\nEnter passphrase:\r\n\r\ngpg: encrypted with 2048-bits RSA key, ID 840212D2, created 2011-11-23\r\n      \" Anouar ADLANI (aadlani) <anouar@adlani.com> \"\r\n```\r\n\r\nThe GPG decryption options:\r\n\r\n* `--decrypt-files` decrypts all files passed in parameter\r\n\r\nReferences:\r\n\r\n* GPG: [The GNU Privacy Guard](http://www.gnupg.org/)\r\n* GPGTools: [Open source initiative to bring OpenPGP to Apple OS\r\n  X](http://www.gpgtools.org/)\r\n* PGP Global Directory: [free service designed to make it easier to find\r\n  and trust PGP\r\nkeys](http://keyserver.pgp.com/vkd/GetWelcomeScreen.event) \r\n* MIT Key Server: [MIT PGP Public Key Server](http://pgp.mit.edu/)\r\n\r\n## Schedule the backup tasks\r\n\r\nHere we are, our script started to be quite complete, but we need now to\r\nexecute the backup task regularly, and for that job we will use the\r\nCRON tool, with our user's crontab.\r\n\r\n### Cron\r\n\r\nVisualize and edit your user crontab:\r\n\r\n```bash\r\ncrontab -l      # List the actual crontab tasks\r\ncrontab -e      # Edit the crontab\r\n```\r\n\r\nCrontab options:\r\n\r\n* `-l` display the CRONTAB of the current user\r\n* `-e` edit the CRONTAB in your `$EDITOR`\r\n\r\nA crontab task has five fields for specifying day, date and time\r\nfollowed by the command to be run at that interval.\r\n\r\n```bash\r\n*  *  *  *  *       command to be executed\r\n-  -  -  -  -\r\n|  |  |  |  +-----  day of week   (0 - 6) (Sunday=0)\r\n|  |  |  +--------  month         (1 - 12)\r\n|  |  +-----------  day of month  (1 - 31)\r\n|  +--------------  hour          (0 - 23)\r\n+-----------------  min           (0 - 59)\r\n```\r\n\r\nTo set our task to be executed every 30 minutes from 8am to 6pm during\r\nthe workdays, that leads to:\r\n\r\n```bash\r\n*/30 8-18 * * 1-5 ~/bin/backup/backup.sh\r\n\r\n```\r\n\r\n * **\\*/30** : \"Every 30 minutes\"\r\n * **8-18** : \"From 8 to 6\"\r\n * **1-5** : \"Workdays\"\r\n\r\nIf you are not comfortable with the CRONTAB syntax, I found some times\r\nago a website which could help you to create your tasks visually, named CORNTAB that you will find in the references.\r\n\r\n* Introduction: [Newbie Introduction to\r\n  cron](http://www.unixgeeks.org/security/newbie/unix/cron-1.html)\r\n* CornTab: [A visual crontab\r\n  utility](http://www.corntab.com/pages/crontab-gui)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration.","tagline":"Pure Unix personal backup manager that I use on OSX","name":"Backup-manager"}